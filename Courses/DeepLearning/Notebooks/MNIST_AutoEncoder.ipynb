{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the relevant modules\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import CNTK\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "    \n",
    "import gzip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import struct\n",
    "import sys\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences\n",
    "\n",
    "https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "\n",
    "https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "\n",
    "https://github.com/altosaar/variational-autoencoder/blob/master/vae.py\n",
    "\n",
    "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is E:\\Temp\\MNIST\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "data_found = False\n",
    "for data_dir in [os.path.join(\"E:\\\\\", \"Temp\", \"MNIST\")]:\n",
    "    train_file = os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file = os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found = True\n",
    "        break\n",
    "\n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "print(\"Data directory is {0}\".format(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "encoding_dim = 32\n",
    "output_dim = input_dim\n",
    "\n",
    "def decoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(input_dim//2, activation = C.relu), \n",
    "                               C.layers.Dense(input_dim, activation=C.sigmoid)])(input)\n",
    "    return intermediate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(input_dim//2, activation = C.relu), \n",
    "                               C.layers.Dense(encoding_dim, activation=C.relu)])(input)\n",
    "    \n",
    "    mu = C.layers.Dense(encoding_dim, activation=None)(intermediate)\n",
    "    sigma = C.layers.Dense(encoding_dim, activation=C.relu)(intermediate)\n",
    "    \n",
    "    return mu, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = {}\n",
    "def train_and_test(reader_train, reader_test, model_func):\n",
    "\n",
    "    ###############################################\n",
    "    # Training the model\n",
    "    ###############################################\n",
    "\n",
    "    # Instantiate the input and the label variables\n",
    "    input = C.input_variable(input_dim)\n",
    "    label = C.input_variable(input_dim)\n",
    "\n",
    "    # Create the model function\n",
    "    mu, sigma = encoder(input/255.0)\n",
    "    \n",
    "    network['mu'] = mu\n",
    "    network['sig'] = sigma\n",
    "    sample = C.random.normal_like(mu, mean=0, scale=1, seed=0)\n",
    "    sample = mu + sigma * sample\n",
    "    network['sample'] = sample\n",
    "    \n",
    "    model = decoder(sample)\n",
    "    \n",
    "    network['decoder'] = model\n",
    "    \n",
    "    \n",
    "    # The labels for this network is same as the input MNIST image.\n",
    "    # Note: Inside the model we are scaling the input to 0-1 range\n",
    "    # Hence we rescale the label to the same range\n",
    "    # We show how one can use their custom loss function\n",
    "    # we will use simple reconstruction error - squared diff \n",
    "    target = label/255.0\n",
    "    loss = C.losses.squared_error(target, model)\n",
    "        \n",
    "    # the above loss doesn't restrict the encoding domain\n",
    "    # in ideal scenario, to generate fake images we want to feed a\n",
    "    # noise to decoder and get real-like images\n",
    "    # inorder to do this, we need encoding domain to be known. Usually we restrict\n",
    "    # the encoding to be N(0,1), we can sample noise from N(0,1) get real-like images\n",
    "    # we want encoder to predict mean and sd for each element and sample from that for decoding\n",
    "    log_stddev = C.log(sigma)\n",
    "    klloss = - 0.5 * (1 + log_stddev - C.square(mu) - C.square(C.exp(log_stddev)))\n",
    "    loss = loss +  klloss\n",
    "\n",
    "    \n",
    "    label_error  = C.classification_error(model, target)\n",
    "\n",
    "    # training config\n",
    "    epoch_size = 30000        # 30000 samples is half the dataset size\n",
    "    minibatch_size = 64\n",
    "    num_sweeps_to_train_with = 20 if isFast else 100\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) // minibatch_size\n",
    "\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = [0.00003]\n",
    "    lr_schedule = C.learning_parameter_schedule_per_sample(lr_per_sample, epoch_size)\n",
    "\n",
    "    # Momentum which is applied on every minibatch_size = 64 samples\n",
    "    momentum_schedule = C.momentum_schedule(0.9126265014311797, minibatch_size)\n",
    "\n",
    "    # We use a variant of the Adam optimizer which is known to work well on this dataset\n",
    "    # Feel free to try other optimizers from\n",
    "    # https://www.cntk.ai/pythondocs/cntk.learner.html#module-cntk.learner\n",
    "    learner = C.fsadagrad(model.parameters,\n",
    "                         lr=lr_schedule, momentum=momentum_schedule)\n",
    "\n",
    "    # Instantiate the trainer\n",
    "    progress_printer = C.logging.ProgressPrinter(0)\n",
    "    trainer = C.Trainer(model, (loss, label_error), learner, progress_printer)\n",
    "\n",
    "    # Map the data streams to the input and labels.\n",
    "    # Note: for autoencoders input == label\n",
    "    input_map = {\n",
    "        input  : reader_train.streams.features,\n",
    "        label  : reader_train.streams.features\n",
    "    }\n",
    "\n",
    "    aggregate_metric = 0\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        # Read a mini batch from the training data file\n",
    "        data = reader_train.next_minibatch(minibatch_size, input_map = input_map)\n",
    "\n",
    "        # Run the trainer on and perform model training\n",
    "        trainer.train_minibatch(data)\n",
    "        samples = trainer.previous_minibatch_sample_count\n",
    "        aggregate_metric += trainer.previous_minibatch_evaluation_average * samples\n",
    "\n",
    "    train_error = (aggregate_metric*100.0) / (trainer.total_number_of_samples_seen)\n",
    "    print(\"Average training error: {0:0.2f}%\".format(train_error))\n",
    "\n",
    "    #############################################################################\n",
    "    # Testing the model\n",
    "    # Note: we use a test file reader to read data different from a training data\n",
    "    #############################################################################\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 32\n",
    "    num_samples = 10000\n",
    "    num_minibatches_to_test = num_samples / test_minibatch_size\n",
    "    test_result = 0.0\n",
    "\n",
    "    # Test error metric calculation\n",
    "    metric_numer    = 0\n",
    "    metric_denom    = 0\n",
    "\n",
    "    test_input_map = {\n",
    "        input  : reader_test.streams.features,\n",
    "        label  : reader_test.streams.features\n",
    "    }\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_test)):\n",
    "\n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions\n",
    "        # with one pixel per dimension that we will encode / decode with the\n",
    "        # trained model.\n",
    "        data = reader_test.next_minibatch(test_minibatch_size,\n",
    "                                       input_map = test_input_map)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual\n",
    "        # minibatch data to be tested with\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "\n",
    "        # minibatch data to be trained with\n",
    "        metric_numer += np.abs(eval_error * test_minibatch_size)\n",
    "        metric_denom += test_minibatch_size\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    test_error = (metric_numer*100.0) / (metric_denom)\n",
    "    print(\"Average test error: {0:0.2f}%\".format(test_error))\n",
    "    \n",
    "    return model, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serajago.FAREAST\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\cntk\\learners\\__init__.py:340: RuntimeWarning: When providing the schedule as a number, epoch_size is ignored\n",
      "  warnings.warn('When providing the schedule as a number, epoch_size is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per 1 samples: 3e-05\n",
      " 6.41e+03   6.41e+03       0.95       0.95            64\n",
      " 6.38e+03   6.37e+03      0.905      0.883           192\n",
      " 6.36e+03   6.35e+03       0.91      0.914           448\n",
      " 6.28e+03   6.21e+03      0.904      0.899           960\n",
      " 5.72e+03    5.2e+03      0.835       0.77          1984\n",
      " 4.17e+03   2.67e+03      0.666      0.503          4032\n",
      " 3.16e+03   2.16e+03      0.553      0.441          8128\n",
      " 2.56e+03   1.97e+03      0.441       0.33         16320\n",
      " 2.11e+03   1.67e+03       0.32      0.199         32704\n",
      "  1.8e+03   1.49e+03      0.224      0.129         65472\n",
      " 1.57e+03   1.34e+03      0.152     0.0797        131008\n",
      " 1.37e+03   1.18e+03      0.103     0.0537        262080\n",
      " 1.22e+03   1.07e+03     0.0715     0.0403        524224\n",
      " 1.07e+03        915     0.0513     0.0311       1048512\n",
      "Average training error: 4.81%\n",
      "Average test error: 2.30%\n"
     ]
    }
   ],
   "source": [
    "isFast = True\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels_viz = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "        features   = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "\n",
    "\n",
    "num_label_classes = 10\n",
    "reader_train = create_reader(train_file, True, input_dim, num_label_classes)\n",
    "reader_test = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "model, simple_ae_train_error, simple_ae_test_error = train_and_test(reader_train,\n",
    "                                                                    reader_test,\n",
    "                                                                    model_func = create_model )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image statistics:\n",
      "Max: 255.00, Median: 0.00, Mean: 8.69, Min: 0.00\n",
      "Decoded image statistics:\n",
      "Max: 218.58, Median: 0.09, Mean: 8.90, Min: 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADDCAYAAABJYEAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfyKPDSLf/ocuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fca745e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read some data to run the eval\n",
    "num_label_classes = 10\n",
    "reader_eval = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "\n",
    "eval_minibatch_size = 50\n",
    "eval_input_map = { input  : reader_eval.streams.features }\n",
    "\n",
    "eval_data = reader_eval.next_minibatch(eval_minibatch_size,\n",
    "                                  input_map = eval_input_map)\n",
    "\n",
    "img_data = eval_data[input].asarray()\n",
    "\n",
    "# Select a random image\n",
    "np.random.seed()\n",
    "idx = np.random.choice(eval_minibatch_size)\n",
    "\n",
    "orig_image = img_data[idx,:,:]\n",
    "decoded_image = model.eval(orig_image)[0]*255\n",
    "\n",
    "# Print image statistics\n",
    "def print_image_stats(img, text):\n",
    "    print(text)\n",
    "    print(\"Max: {0:.2f}, Median: {1:.2f}, Mean: {2:.2f}, Min: {3:.2f}\".format(np.max(img),\n",
    "                                                                              np.median(img),\n",
    "                                                                              np.mean(img),\n",
    "                                                                              np.min(img)))\n",
    "\n",
    "# Print original image\n",
    "print_image_stats(orig_image, \"Original image statistics:\")\n",
    "\n",
    "# Print decoded image\n",
    "print_image_stats(decoded_image, \"Decoded image statistics:\")\n",
    "\n",
    "\n",
    "# Define a helper function to plot a pair of images\n",
    "def plot_image_pair(img1, text1, img2, text2):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 6))\n",
    "\n",
    "    axes[0].imshow(img1, cmap=\"gray\")\n",
    "    axes[0].set_title(text1)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(img2, cmap=\"gray\")\n",
    "    axes[1].set_title(text2)\n",
    "    axes[1].axis(\"off\")\n",
    "# Plot the original and the decoded image\n",
    "img1 = orig_image.reshape(28,28)\n",
    "text1 = 'Original image'\n",
    "\n",
    "img2 = decoded_image.reshape(28,28)\n",
    "text2 = 'Decoded image'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.90968335,  2.20867872,  1.4796083 , -0.44815561,  0.58176023,\n",
       "        -0.26275915,  0.08692706,  2.02647591, -0.01705982,  0.8139292 ,\n",
       "         0.76978421,  0.33688191,  0.00991692,  0.10844822,  2.92631364,\n",
       "        -0.47910967, -3.16812038, -0.44592249,  0.16960302,  0.79770142,\n",
       "        -0.50770295, -1.05912542, -0.34381834,  0.28639558, -1.32266712,\n",
       "        -0.71272862, -1.50824451,  1.39378762, -1.2384702 , -2.65677571,\n",
       "         0.15963128,  2.54456973]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random image\n",
    "np.random.seed()\n",
    "idx = np.random.choice(eval_minibatch_size)\n",
    "network['mu'].eval(img_data[idx,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
