{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the relevant modules\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import CNTK\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "    \n",
    "import gzip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import struct\n",
    "import sys\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences\n",
    "\n",
    "https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "\n",
    "https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "\n",
    "https://github.com/altosaar/variational-autoencoder/blob/master/vae.py\n",
    "\n",
    "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is E:\\Temp\\MNIST\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "data_found = False\n",
    "for data_dir in [os.path.join(\"E:\\\\\", \"Temp\", \"MNIST\")]:\n",
    "    train_file = os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file = os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found = True\n",
    "        break\n",
    "\n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "print(\"Data directory is {0}\".format(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "encoding_dim = 32\n",
    "output_dim = input_dim\n",
    "# training config\n",
    "epoch_size = 30000        # 30000 samples is half the dataset size\n",
    "minibatch_size = 64\n",
    "num_sweeps_to_train_with = 20 if isFast else 100\n",
    "num_samples_per_sweep = 60000\n",
    "    \n",
    "\n",
    "\n",
    "def decoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(input_dim//2, activation = C.relu), \n",
    "                               C.layers.Dense(input_dim, activation=C.sigmoid)])(input)\n",
    "    return intermediate\n",
    "    \n",
    "def encoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(input_dim//2, activation = C.relu), \n",
    "                               C.layers.Dense(encoding_dim, activation=C.relu)])(input)\n",
    "    \n",
    "    mu = C.layers.Dense(encoding_dim, activation=None)(intermediate)\n",
    "    sigma = C.layers.Dense(encoding_dim, activation=C.relu)(intermediate)\n",
    "\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = {}\n",
    "def create_network():\n",
    "    \n",
    "    input = C.input_variable(input_dim)\n",
    "    label = C.input_variable(input_dim)\n",
    "    network['input'] = input\n",
    "    network['label'] = label\n",
    "\n",
    "    # Create the model function\n",
    "    mu, sigma = encoder(input/255.0)\n",
    "    network['mu'] = mu\n",
    "    network['sigma'] = sigma\n",
    "    sample = C.random.normal_like(mu, mean=0, scale=1)\n",
    "    sample = mu + sigma * sample       \n",
    "    model = decoder(sample)    \n",
    "    network['decoding'] = model\n",
    "    return network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_test(reader_train, reader_test):\n",
    "\n",
    "    ###############################################\n",
    "    # Training the model\n",
    "    ###############################################\n",
    "\n",
    "    # Instantiate the input and the label variables\n",
    "    network = create_network()    \n",
    "    \n",
    "    # The labels for this network is same as the input MNIST image.\n",
    "    # Note: Inside the model we are scaling the input to 0-1 range\n",
    "    # Hence we rescale the label to the same range\n",
    "    # We show how one can use their custom loss function\n",
    "    # we will use simple reconstruction error - squared diff \n",
    "    label = network['label']\n",
    "    input = network['input']\n",
    "    model = network['decoding']\n",
    "    mu = network['mu']\n",
    "    sigma = network['sigma']\n",
    "    target = network['label']/255.0\n",
    "    loss = C.losses.squared_error(target,model)\n",
    "    \n",
    "    # the above loss doesn't restrict the encoding domain\n",
    "    # in ideal scenario, to generate fake images we want to feed a\n",
    "    # noise to decoder and get real-like images\n",
    "    # inorder to do this, we need encoding domain to be known. Usually we restrict\n",
    "    # the encoding to be N(0,1), we can sample noise from N(0,1) get real-like images\n",
    "    # we want encoder to predict mean and sd for each element and sample from that for decoding\n",
    "    log_stddev = C.log(sigma)\n",
    "    klloss = - 0.5 * (1 + log_stddev - C.square(mu) - C.square(C.exp(log_stddev)))\n",
    "    loss = loss +  klloss\n",
    "\n",
    "    \n",
    "    label_error  = C.classification_error(model, target)\n",
    "\n",
    "    \n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) // minibatch_size\n",
    "\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = [0.00003]\n",
    "    lr_schedule = C.learning_parameter_schedule_per_sample(lr_per_sample, epoch_size)\n",
    "\n",
    "    # Momentum which is applied on every minibatch_size = 64 samples\n",
    "    momentum_schedule = C.momentum_schedule(0.9126265014311797, minibatch_size)\n",
    "\n",
    "    # We use a variant of the Adam optimizer which is known to work well on this dataset\n",
    "    # Feel free to try other optimizers from\n",
    "    # https://www.cntk.ai/pythondocs/cntk.learner.html#module-cntk.learner\n",
    "    learner = C.fsadagrad(model.parameters,\n",
    "                         lr=lr_schedule, momentum=momentum_schedule)\n",
    "\n",
    "    # Instantiate the trainer\n",
    "    progress_printer = C.logging.ProgressPrinter(0)\n",
    "    trainer = C.Trainer(model, (loss, label_error), learner, progress_printer)\n",
    "\n",
    "    # Map the data streams to the input and labels.\n",
    "    # Note: for autoencoders input == label\n",
    "    input_map = {\n",
    "        input  : reader_train.streams.features,\n",
    "        label  : reader_train.streams.features\n",
    "    }\n",
    "\n",
    "    aggregate_metric = 0\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        # Read a mini batch from the training data file\n",
    "        data = reader_train.next_minibatch(minibatch_size, input_map = input_map)\n",
    "\n",
    "        # Run the trainer on and perform model training\n",
    "        trainer.train_minibatch(data)\n",
    "        samples = trainer.previous_minibatch_sample_count\n",
    "        aggregate_metric += trainer.previous_minibatch_evaluation_average * samples\n",
    "\n",
    "    train_error = (aggregate_metric*100.0) / (trainer.total_number_of_samples_seen)\n",
    "    print(\"Average training error: {0:0.2f}%\".format(train_error))\n",
    "\n",
    "    #############################################################################\n",
    "    # Testing the model\n",
    "    # Note: we use a test file reader to read data different from a training data\n",
    "    #############################################################################\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 32\n",
    "    num_samples = 10000\n",
    "    num_minibatches_to_test = num_samples / test_minibatch_size\n",
    "    test_result = 0.0\n",
    "\n",
    "    # Test error metric calculation\n",
    "    metric_numer    = 0\n",
    "    metric_denom    = 0\n",
    "\n",
    "    test_input_map = {\n",
    "        input  : reader_test.streams.features,\n",
    "        label  : reader_test.streams.features\n",
    "    }\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_test)):\n",
    "\n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions\n",
    "        # with one pixel per dimension that we will encode / decode with the\n",
    "        # trained model.\n",
    "        data = reader_test.next_minibatch(test_minibatch_size,\n",
    "                                       input_map = test_input_map)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual\n",
    "        # minibatch data to be tested with\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "\n",
    "        # minibatch data to be trained with\n",
    "        metric_numer += np.abs(eval_error * test_minibatch_size)\n",
    "        metric_denom += test_minibatch_size\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    test_error = (metric_numer*100.0) / (metric_denom)\n",
    "    print(\"Average test error: {0:0.2f}%\".format(test_error))\n",
    "    \n",
    "    return model, train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serajago.FAREAST\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\cntk\\learners\\__init__.py:340: RuntimeWarning: When providing the schedule as a number, epoch_size is ignored\n",
      "  warnings.warn('When providing the schedule as a number, epoch_size is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per 1 samples: 3e-05\n",
      " 6.41e+03   6.41e+03       0.88       0.88            64\n",
      " 6.38e+03   6.37e+03      0.896      0.903           192\n",
      " 6.36e+03   6.34e+03      0.913      0.927           448\n",
      " 6.26e+03   6.18e+03      0.884      0.858           960\n",
      " 5.56e+03    4.9e+03      0.819      0.757          1984\n",
      " 4.03e+03   2.54e+03      0.664      0.515          4032\n",
      " 3.07e+03   2.13e+03      0.563      0.462          8128\n",
      " 2.51e+03   1.96e+03      0.446      0.331         16320\n",
      " 2.09e+03   1.67e+03      0.322      0.199         32704\n",
      " 1.77e+03   1.45e+03       0.23      0.138         65472\n",
      " 1.54e+03   1.31e+03      0.159     0.0885        131008\n",
      " 1.38e+03   1.23e+03      0.108     0.0567        262080\n",
      " 1.27e+03   1.15e+03     0.0757     0.0434        524224\n",
      " 1.13e+03        998     0.0529     0.0302       1048512\n",
      "Average training error: 4.95%\n",
      "Average test error: 2.23%\n"
     ]
    }
   ],
   "source": [
    "isFast = True\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels_viz = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "        features   = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "\n",
    "\n",
    "num_label_classes = 10\n",
    "reader_train = create_reader(train_file, True, input_dim, num_label_classes)\n",
    "reader_test = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "model, simple_ae_train_error, simple_ae_test_error = train_and_test(reader_train,\n",
    "                                                                    reader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image statistics:\n",
      "Max: 255.00, Median: 0.00, Mean: 12.59, Min: 0.00\n",
      "Decoded image statistics:\n",
      "Max: 246.16, Median: 0.13, Mean: 12.88, Min: 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAADXCAYAAAA5i3frAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAIABJREFUeJztnX2QdHlV37+ne157enpedjHLs+yy7oorwUqFSBEkCoEK\nxmAorASl3EogUhEilESSSioUsYpgKhZEEo0RDFE3RdCgVgwaq6QQ0ERjBSRRA0QpJCyuyAP7PM+8\ndPf09PTLL3/ce+6ePvO73fPMc2em7+3vp+pWd8/t15k+8/2dl985EkIAIYQQUhS1q34DhBBCqgWF\nhRBCSKFQWAghhBQKhYUQQkihUFgIIYQUCoWFEEJIoVBYCCGEFAqF5Q4QkXeLyHtu4/6PiMgfFPwe\nPi8ir5ly/lMi8reLfE1CrhIReVxEXnUHj39IRMYicn/O+ftE5FBEHjjvayw6Cy8sIvINIvJLInJT\nRDoi8mkRebOILM16bAjhe0MIrz3ra4UQfjaE8Mw7e8e3Rwjh60MI//EyX5OUHxH5DRHpi8iBiOyJ\nyBdE5BdF5KVX/d4KIndneAjh8RBCK4Tw2CW+n0qx0MIiIi8G8JsAPgXgmQC2AbwOwN8B8IEpj6uL\niFzGeyTkiggA3h5C2Aoh7AD4BgC/BuD9IvKDV/vWyLyz0MIC4F0AfiGE8JYQwldCCMMQwm8BeDmA\nbxGR7wQAEXlh6jq/UkQ+A6AD4Cki8qiIvFefTES+RkQ+mq7yPi0if9e63CLyahF53Nz/URH5TyLy\nYyJyQ0S+JCJvM+dXReTnReRPUtf8D0Tk9bfzAW2oTESenr6f7xaR3089tP8uIveKyBtE5DERuSUi\nP2GFU0T+Xfo8bRH5nIi81b3GV4nIB9KV7R+lIb+xiLzA3Ocvisivp5/z8yLyNhFZ9O9faQgh3Agh\nvBvA9wN4s4g8qOdE5FUi8nsisi8inxSRV9rHisg3ishHROSJ9O//ERFZTc9dE5GfE5Hr6ff//SLy\nVPPYDRH5qfRxj4vIG/17E5GvE5H/mj7H4yLy4yLSMOcfFJEPq10CeNG0z2rs5MH09qvT5/3e1Eba\nIvLTItIUkXel7+2LIvJa8xz3mPd0mP5+XuFe57ki8vH0fX1cRN4kImN3n6m/27klhLCQB4BnABgD\neHHO+d8C8N70+gvT+/5nADsAlpGI8qPmPnUAfwjg3QBWATwVwG8DGAG4P73PqwH8sXmNRwH0AHwH\nAAHwPAAnAF6Ynl9LH7OZ3v5rAI4BvMQ8x+cBvGbK58zOA3h6+jk+COAuAA0kHtsfAvih9HM9BGAP\nwCvNc7wGwN3p9ecCuAHge8z5jwD4JQAtAFtIvL0RgBek5x8G0Daf8z4AvwvgzVf9PeCR+735dQBv\ni/x8DcBQ//5IvPvHADw7vf18AAcAnp/efhaAIwB/L33sEoAXGBv6XQDvA9BMvz8/B+B3AEj6+PcA\n+ERqT+sAfjq1kVel5+8C8BUAb0yfexfAhwC8Jz1fA/BpAD+Zvv41AB+zdhn5jE9Pzz+Y3n41gAGA\ndwBYAfAAgJtIIh0vT7/TfzN9X/emj7kXwLen77kO4LvT889Mz2+ldvSW9H1/LYDPABiZ9zH1dzvP\nx5W/gSs0nOenX56Hc86/H8AH0+svTO/7Ne4+Vli+Kf3yNcz5b8NsYfmwe86PA/hHU973BwD8S3P7\nPMLyfHP+jUj+6Yv52S8DeOeU5/wRJJ4eADwtfc6HzflnpT9TYflRAD/jnuMRAJ+96u8Bj9y/cVRY\n0nPXAfyT9Prvwywy0p+9B0/+Y/8xAL+c8zzPQyJSLfOz3dRmnpv+w+4BeKk530rPq7C8CcD/cM/7\nl5AswCS9PgDQNOf/OmYLyxiTwnIEoG7u84sAftU97gDAy6b8Tn8PwBvS638LwJ+682/ApLBM/d3O\n8zEzQV1hnkDyxbsXyUrB8zQA/8/97LEpz3cNwK0QwtEZ76/8qbvdBbAJACKyAuBfAHgZgD+DJO69\njuQLfF4Ckn8M9vWeCOm31r+H9H28BcB3IfmMQLLy+530+rX0Of/YPP4x95rPAPCXReSW+VkNye+f\nlAgRWQPwFCSrbSD5275TRN6ud0GyQv9v6e2vBpBXCXkfEps51B+EEG6JyB6A+5F8j1Zhvk8hhEP3\nPXoGgOdEvlsjAPcgse+9EELHnP/8mT7sJDdCCCNzuwtg393nCE/a7jYSD+evIBHLAGADwFel970G\n4HH3+Mfc7Vm/27llYWPcIYTPAvgjAKfKFkXkYSQrpl9xp8b+voYvAtgVkQ3zswfu8G3+QyRez7eF\nELZDkkT9IC7xH7KIfBeAv49khXVXCGEXyapJ38MX08unm4c94J7mOoCfDSHsmmM7hLB1gW+dXAyP\nILGDj6a3rwN4vfm77oSkoupl6fnHkIR5YjwOYEdEsu+BiOwiCTd/Acnirw/zfUrvu2Oe4zqA34x8\ntzZCCF8C8Cfpa2yax3z1GT7nnc4TeTuSEPA3G9v9v5i0m/vcYx5wt7+E6b/buWVhhSXl9QC+U0T+\neZqAXhKRb0ISbvo1AL9wG8/1PwF8DsA7RGRdRK4BePMdvr8WEsO6KUkl2ncA+JY7fM7bFaUWklDC\nDQAQkRchERkAQAjhiwB+A8APichWulL7QUwa5rsAvEJEXiEiyyJSk2QvwV+9g89BLhERuVtEXgfg\nXwN4RwhBvfkfAfADIvIcSVhNr/+F9Py7AbxERF4rImupjb1ARJaRhH0/BeDfishmKho/DuB/A/hE\n6kW/D8Bb0yT/BoAfxuQC71EAz04T6+vpe71PRF6env8YgM8C+Fci0hCRe5HkNWZ+5HP9op6khcSD\n2RORFRH5PiQhYuVXAKxIsrVhWUS+FsD3uef4UUz/3c4tCy0sIYQPA/hmAH8OSQL7AMC/B/BeAC93\n4aFZzzVCErL6swC+jESYfiY9fXw7b8tc/2EkK64vIFnhvAjAf5ly/1nPd5b7e/4DkuT8J5GsIF8L\nwO+LeQSJIX4BwP9CksgXpJ87hPAJAC8B8D1IPscNJKId3aBG5oZ/nFY07SP5Z/+tAB4JIWT/mEMI\n/wbAWwH8BJKE9uNIQkCN9PynkYSDHkHyt78O4AcA1EIIYyT5jlUk0YPPIPmfZG3vTUi+e59EYqP/\nByaUG0J4HMA3Ivl+fS4No/0qgK9Pz6tdPojEA/gQkkT+LM7jsdjH/FMkv4MvIwmpPwVJQZC+7wMA\nLwXwN5D83t4H4KeQLCT1PlN/t/OM3Mb/TnKbiMi3IwkBzf0XoUhE5M8jEZhrIYQvX/X7IaQMiMj3\nA3hduORN1BfBQnssRSMizxORZ6TXHwbwz/Ck11JZRORZIvLs1F1/GoB3AvgoRYWQfETkxam9QESe\ngySn+r6rfVfFQGEplqcC+JCIdJCEwn4bwD+42rd0KWwhKc8+RFIt9hWYPAwhJMrXAfhY+v/i55GE\n4N9xtW+pGBgKI4QQUij0WAghhBTKpW6QFBG6R2TuCSFc+cZN2gopA3m2Qo+FEEJIoVBYCCGEFAqF\nhRBCSKFQWAghhBQKhYUQQkihUFgIIYQUCoWFEEJIoVBYCCGEFAqFhRBCSKFQWAghhBQKhYUQQkih\nUFgIIYQUCoWFEEJIoVxqd2NCCKk6ItObYy/CDCwKCyGEnIOYgPifLYKIxKCwEELIGfHCMeu2RUVG\nRCovOBQWQgg5A1Y09PpZhaXqQuKhsBBCyBnxghITG0/MU6m610JhIYSQGeR5K9OEJYQw8bMqC4mH\nwrLg5BmJYo0h7zohVSMW4so78gghRO1kEbwWCsuC4I2hVquhVqthdXUVKysr2eXKygqWlpYwHA4x\nGAwwHA6zYzAYYDQaTRzD4RDj8fiqPx4h58J7HNY2/FGv17NLvV6r1TAej6PHaDSKXirq0VRRXCgs\nC0LMUFZWVtBsNrNjc3MTzWYTq6ur6PV6OD4+PnWcnJzg5OQE/X4fJycnCCFQWEgpsR6HFZWlpSXU\n63UsLS1NXF9eXs5+ptdrtdqpxZe9rYuv4XAI4LSnX0VRASgsC4E1GjWSer2OtbU1tFot7O7uThyN\nRgOdTid69Ho99Ho91GpJ04bRaITBYHDFn5CQ2yMvrKX2sbKyguXl5eilPer1+qnFlh6DwQAnJyeZ\neI3H4+x6VQVFobAsCNZo9FBhufvuu3HPPfdkx+bmJvb3908dy8vLWF5eRq1WQwgBw+EQ/X7/qj8a\nIefGLrrURlRAVldXs2NtbS27tNfr9XrmzXsvv9/vTwiJho9jXn7VhIbCsgDYuLEazvLyciYsd911\nF65du4b77rsP999/P3Z2dnDjxg3cuHEDTzzxBNbX1zNBqdfrABJP5eTkJLtNSNnwomLtY2VlBWtr\na1hfXz91NBqN7PrS0hKOjo7Q7XaxurqKbreLer0+EWZTUdHX0dfWc1WEwrIgeI9lZWUF6+vrmcdy\n7do1PPDAA3jooYdw99134/r169jc3MTa2hqWl5chIhiPxxOeytHRURYSI6RM5BWzqI2srq5mIrKx\nsZFd+mNpaQmdTicrftGkvqKiMhgMMsHR12fynpQan1+xbr7GjtUg7ErKVrfYZKRWt1TRIEj1iVWC\nWXHR5LwXFxUYPdRjGQ6HWY5F85f6XLGy5EWwGwrLguDd/GnCovX3KioqLFrxosJCcSFlxnoP3mNR\nG1lbW0Oj0UCz2cwExQrM0tISBoMB+v1+1JbymlL6y6pBYVkA8jyWtbW1zBi0dFKJCYv1WlRUqmoY\npJrM2vg4zWOx3ooe9Xod/X4fx8fHmR3FPBbLItgMhWVB8Il767FYY/Aey3g8PrVBUgVnEQyEVJO8\nHIsKiy6+rLDodRsK06owu7k4LxTmF2JVth8KywIQq9G3JZTWY7E197M8FobCSJnIm58S28eii6+1\ntbUsv2IrwvSyVquh1+tlduRDYdamLFW3GwrLghDLsdhQmK1m8R5LXo6FoTBSZmLlxrM8Fl9uLCK5\n3n9MVBbFZigsC4CNHceqwtQYrLeiQqIbv7rdLrrdLo6OjrLWLsPhcCGMhJSfaT3BdMHlbcNuiPSL\nMFs96fORuhDzFZR5tlJFG6KwLAh5ORa7m17jwCosJycnOD4+xtHRETqdDtrtdtbSRYWFfcJImfCV\nYDb0pXbhQ8V+EeZzkV5QBoPBhHfvxcUfVYTCsgDMqgrL81hiwtLv97OeSBQWUiZiDSf9pmHvsUzL\nRebt9fKH7WxcZTGxUFgWhGn7WLyxqJFYYel2u2i329lqTFdkFBZSRmIei7cL3xtM2+VrG6O8ENgs\nj0UfW2WBobAsAHlVYbEciw2FaX2+9VhsubGfL0HIPJK3095XgdmuxTGvxT/WhsHyvBVrJ7aKkhsk\nSSXwqzM1lrxS47xQGFB9oyDVI7YxMi/HkhcKi4lCXijMzmXJE5UqQ2GpGLEZE741xebmJra2ttBq\ntdBoNLImk8PhEL1eDwDQ7Xaz1t8Me5Eq4D0XOw0yNmtFD118WYGwm4etiOgMFg2HTasMq7LAUFgq\nRN5YVRWVjY2NTFS2t7exvb2deS0hBJycnKDb7WI0GqHT6eDo6CgTFooKqRq+6aQf0a1ejCb3tbze\n5lZsztEKiha3aDis6jkVD4WlYmjcWA8d6LW+vj4hLDs7O9je3p6YsaIrrH6/j263i16vh36/T2+F\nVIZp5cYxT8WKix3QZb0VLy5WYGKhsEWAwlIhYsaisyVsGKzVamF7extbW1sTyfiTkxOMRqMsp6L7\nVeixkCoRS97bcuOYt1Kv1zEajU4VuNgQmD+mjZmoushwSlPFiM2UiIXC1GPZ2NjA8vIygMRj6Xa7\nODw8nAiF0WMhVSSv3DhPYGzLo1goLBYW8y2Q9PFVh8JSIfLc+1goTHMsKiw2x6LCwlAYqSqxli7T\nwmB+E7HfsxILhS3yYDyGwipGrDY/VkKpK7NarZaNGz4+Ps6ExeZYGAojVcP2z4tthrTVYH6PlwqI\n9tE7Pj4+VUFpd9z7jZGLAD2WCjEtIWlXX5rY1zn2doZ9u92eEBa2biFVIDZ/xXei0I7FttWR70hh\nRUU7UtjGrD5hbxP3iyIqAD2WyuGn4MXq8f1QL+1ibDdCMhRGqkLezvtY77z19fWZXb/7/X7W8Vtz\nkd5jiTWeXCQoLBViWv8jHytWYfHG0ul0TnksDIWRKhArNVZPXkXlvB6LLsKshx/raLwoUFgqxrTd\nxLFE5KxQmHosi2QUpHpYUdFL77GosNgci82v5DVn9R6LJuwXVVQACkulsPFjX5tvx6Z6j2UwGGTC\nwlAYqSp5myNt5aQKi0/cA5iwlV6vlwmLJvB9jmVRGk7GoLBUCBGZMJSNjY1sU+TGxkZmMFqPb0sm\nbSdj3yeMXYxJWYkl7fMKXPy4br9vJc9WvLB4e1kkQVEoLBVChUVFpdVqYXd3F7u7u9jc3ESj0chK\njO3mLh3epWWTsUTkIhoHqQZeUGy7I/Xk7eZIP1HVhsDUTtRjsfkVisqTsNy4QtRqtSwRqcKys7OD\nnZ2drJPxyspKFgLTzVxqMFZcfCJyUQ2ElJtYibFt4+I9ltXV1VN7V7xn70Nh3ltZxNCXhx5LhYh5\nLDs7O5nHsr6+nq3GdGVlxcV6LNZQ6LGQMuO7fntvxRe5aA4SwCmPxdqJeivWY+FCLIHCUiHUY1ld\nXcXGxga2trawu7uLnZ0dNBqNUx6Llk7qKsx6LH5m96IbCikneR7LtJHEsSmRNmxsQ2HdbjezIW3i\nynwkhaVSiEg0FLa7uztRGVar1SaExcaO1Wi0HYVtS0FIGbGiYj0WHw5TYQEwUSZsJ6qqraincnR0\ndKqjMW2FwlJ6bAmlGonvZry5uTmxUrP7V3wzPQ2B2Sl5i1iHT4rDjwU+C0V832Leik/Yx5pO2hn1\ndqREzLvXcnw/237RobCUFDUWazyx0kndSezvDyAqHnaVtqibu0hxnEdUinxdO/jOt2/Ja3Wk3307\nx15DXXmzVhaxg/E0KCwlJG8Esa9usR1bgdMbtbyQ5DXNo7iQ83DVoqLXY+OH9fCt8W2ZsQ2BqbB4\ncYm1byEUltISS0bGPBY9vHDkeSk0ElIEVyUqnrxOxn62ve36raFgv3/Fei12nj3t5jQUlhISixvb\n9i3eW1lbW5vIp1hPxBuFjRGzHp+ch6sUlVgnY9/iSG3Dboi0UyJjTSe9txLrYsxQ2JNQWEpKXk2+\nFxfNsaiB2LGq3mthXoXcKfPkqejl7XgssTYusVCYLcfX+9N2noTCUkKmtcf3EyJVcMbjMer1+ilD\nyAuNEZLHvIjHWZjWxdj2BfPC4kXFdqPw3gpA795DYSkhKix2pr2WGNtZErYzKzAZ+vKJR8aHSdmJ\ntca344fVRprNJprN5il7yRMV22zStzoCKCYx2CushNhVmC0r9kOKbL8jG+rSMklbLklRIVXCluFb\nb+UswhJCiM5diTWbtDZD+3kSCktJsSWU6t43Go1oh1bgdOjLCwvFhVQBu08LwER+RRdgGxsb2NjY\nmOmx6Mhu3WHve4JRVPJhKKyEqMdiQ2GNRiPXYwEmhYWiQqqOrwg7SyjMdqXQ3fbqscSmRLIKLB96\nLCUkLxQ2K8fi21T43cMUF1IlvLCcNRRmcyyxUJjPsZDT0GMpIX43cd68br+L2Lf/tkbCrqzkrExb\nfNxuxViRCxk/LRLAKY/FhsLUw9eqsLwd99pw0vcG4yIsHwpLCcmrzbd1+XaufQgha/nd7XZxeHiI\ndruNW7du4eDgIJtvr22/CTkvIYQrKUe2lWB5I4i9d29n26ut+Byk5lr8fCKGwabDUFgJmbaPxYbB\nrLAMh0McHx9nwnLr1q0JYTk+PsZgMKDXQu6Yq/qH60XF2ojdcR/LR/qNkV5U1LO33gqFJR8KS0mJ\nGY1dgfnNXlrhosKyt7cX9VgoLKQIruKfrm+TH/NYNGRsw8YxYbGVYdZj8W1cSByGwkpIzGPxu+1j\nHosNhe3t7eHmzZsTwqKuPiFFcJlhMb8pMi9crB5Lo9GYGPaV57ForsX2B+PMldlQWEqIrspi/Y+8\nx5IXCvMei865p8GQIrlscTlrjmV9fX1iomSs0MWOJGaO5fagsJSI2LRIazBWXGyp8Xg8niidVGHZ\n29tDu93OSimZYyEXwWX8A87Lr/hxEn74nZ9v78vxbRUlcyxnh8Iyx3hj0evqyjebTbRaLbRaLWxt\nbaHVaqHRaGBlZQW1Wg0hhMwg7A5ircvvdrvRTV+ElAlbWmxb5Gv+0Y4d1p/X6/VMGKz3Ydvi502L\npKjMhsIy59hBXurW6zz7ZrOJzc3NqLDU6/XMUzk5Oclq8WcJCw2GlIlYe3z1UtRTiYlKvV4/NaRL\n7cVPiIwN9aK4TIfCMsf4jZB6qcKi4mKFRRP4Orvb9jtSYel2u5nA6GS8WP8jQsqCzTtO81ZUVNSj\n941Zp3krzK+cHQrLHGMNxSbpdfewDYVtb2+j1WplRqPCorkV661Yj8UaEUNhpEzEZtvbhZjNrdjF\nmQqMftc1p+IFJc9j4bTI2VBY5phYryMtl8wLhflJkBoGi+VYjo6OTq3IaCykrOQl7H0ozO60BzCR\nrI95LD7HQlGZDYVljsnrCZYnLJubmxOlkXrdhsJ6vV7mrXS73VNCRI+FlJG8UFhMXFR8fHmxtx0V\nmpi4MMcyHe68n2PsXhUrKr4lhe13pNidw3kbvKxx0FBIWbGikjfbXkvwY3Ptraj4ufYcL3E+KCxz\nTN7cFduZNW+nve9k7OvwOeOelBm/6dJ6977NkZ9rb7sfx/qCTSs1pricDYbC5hi7c9gm7a3H4nfb\n+9bf3li8kQD0Vkj5yWvh4oVFE/zAk9/7WYswX5bMBdlsKCxzjA+FeY8lZjQAMmNRUbHlxLEmev6S\nkLLg97H4CsppHosPhcXCxnm5FdrKdCgsc4wPhU3LscT6HflVmB+pSkEhVcE3Zp0mLHkNJ62dxBZi\n9iDTobDMMTGPxU+/iw0rsu69b/nNtt+kikzrZhxbfCm6APOzV2KbI623Qq9lOkzezzGz4saxLsbq\n1muJcafTQafTwdHRUdbBmPO6SRXwUyP9COJmszkRNrbNWX242Jbh+9n2XlQAevmzoLDMMWepdPGu\nvbr02iK/3W5PdDBWY6FhkLLid9wDp2fba5PWacKiXorOtbfC4hdh9FRuDwrLnJPnseTNXRmNRhMt\n8judTiYsaixs3UKqRKxDhQpLs9nM5ttrc1bvsaiw2I4Uais6SoKicntQWOaYs5RQxjwWNRYrLD4U\nRgMhZcbvY7F2YqsnbT7Sl+R7YTlLKAxgGOwsMHk/x8wKhXmPRStcrMeSFwqjx0LKjh/UFQuFNZvN\nidL8er0OYLLxZL/fz0LH1mOxnSq8t0JxmQ6FZY6Z1qbCNtXT1ZvPsajHEkve0zBIlfA5Fk3e21BY\nXvLeeiydTmdqjoWcDQrLHGGrXACc8lR0JaYllEtLyZ/PCoquvmwYzIfCmGMhZcVOVbWXsdESut8r\nb1y3DRvbRq02v8LS/PNBYZkTrJF41169FDuv2yYidaCXNRB16+mxkKrhR3bHZhZZW8nzVmy5sRWW\nWH6F3B4UljnAr8D0sDMl1FB0FWbjxT5WbGeuqMfiJ0XSYyFlxRa12KS9biRWYdFDz03rpafhMO+x\n0Fs5HxSWOSFmLHYOixpJrMJFPRY/LVJDYZ1O59SkSBoLKSN53oqdv2I9lvX19YmpqjFh8aEweix3\nDoVlDogZi5+C5+PGvi3FeDzODYW12+2sCsY21COkjFh7UVuZFgrz1WOxlkdWWGyHY9rK+aCwzAl5\nq7CYx7K+vp4Jhb20wuI9FnYyJlVgmqjYuUVWWABMbHCMDfiytmN7h9FjOR8UljnAdzHWw7akUGPR\narDBYAAAWRhsOBzi+PgYx8fHmStvG+kRUgVsBZjd02XnFPmOxioi6qmozeQdvk0+uX0oLHOAJuo1\n3KUisrW1lYmL7dJqN0Tadt8aH/YbuwipCrpfRdu2qAffarWyPSt2AVar1TI70PDXcDicWHzZBRgH\nehUDhWUOsMaiUyI3NjbQarWwubk5sRLTpD1wekOkVrMw8Uiqii7CfAdjKyyxfSt5kyLtOAkvLhSV\n80NhmQP8KqzZbGJzczO6Cot5LLZNvnosdOVJ1fDNJnUR1mq1Mlvx+7y0j9602fbT5q6Q80FhmQN8\nKKzZbGJra2siFKZ7V6zHYkNhNr9ijYXGQaqAbY+vtqKLsK2trVOLsNi4bluWH5sW6b0Vei3nh8Iy\nB2hCMmYsGgqzO4jtKiwmLL7HESFlxpbWq8diQ2HWY4m1yAdOh8J0ARabbc/ZK3cOhWUO0KowrXax\nZcWxFvnWWGw4zLv1NApSdnz/PDuqWxdhugDTIhfNReaNk9BFWF5PMArKnUNhmQO0Nt/vX9Hrduew\nYuvx9WDikVQJP3oYmBQWzbFsbm5OePaxvmBaCWb3eamHrx6L9/BpP+eHwjIH+E1fXlysp6LGAkyK\ni6+958qLVAG/a97nI6cJCzA5d8WOk4h1Mebm4eLgBMk5IdbOJSYsSsxjsV4LRYVUAS8sMY8lVj0Z\nm7tihcV6LDYUplBk7gwKyxwQ81isqOQJixcUHwojpKzY8Je9rfZhKyjVY9nY2JjYwwJMlhnHQmHe\nY6HdFANDYXNCXu+jvFBYrO8RdwyTqnEWj0WFxbY9muWx+CmRsVAY7ef8UFjmALvxyzedtD2PfE2+\nb6Lne4TRcyFlxnf9js1e8cPvzjIpUmcVxUJhtJdioLDMAVZUdPywbow8y7xuNRSd122NhYZCyorv\n+K12YgtcZhW52L1edra9ei20lYuBOZY5QF18OylS+4XFZnarsNg5En4EMSdFkjLjK8HyRMUeefu8\n7CJM8yvdbneqsFBk7gwKyxxgXXy78WuWsFhj0cFedgIeV2GkzPi5K7NEJVbkEguFqccyrSqM3BkM\nhc0B2tIl5rHYVi52FLEPhcU8FgoLKSveY5kmLHll+XmhsJjHMhwOmbQvEArLHOCrXazHokO/8jwW\nP4qYcWNSFWJTVfPyK1rcMq3lkbUVzbHENkiSO4fCcsn43kcicmq2ve0Vlhc/tvX5drQqq8JIFYjt\n61L70Kr3MdCPAAAIQElEQVQwv9fL732ZNYI41rCV9lIMFJZLxBqLLaH0o4djmyN97JiQKqN2Yhdb\nWjHp8462h54yHo8hItnGYTvHPtYqn6JSLBSWS8Q3mtRDhcXO8J61GiOkytjZ9urBNxqNU8KiITAb\n/gohnGpAaYd8xVrlM3FfLBSWS8Rv8FIBscLiRcV6NhQXsij4SkktaPGziWIJ+1hXCjt+mB7LxUNh\nuUSsx6IuvhpNTFiWlpYmEpgUFbIo2EpJKyx2mqpOVFXb8F2/1WM5SyiMHkuxUFguEVv9ZUuLrXvv\nPRbfK4mQReB2PJZZPfTyxIUey8VBYblEYk30NG6cl7y3+FWYP2y3YxoKKSN2tr1vc5TXjcL20LNd\nv30IzAqLz6/QVoqFwnKJqLGot9JoNLJ233ZWt4bA/OpLr2u5pB46X8K2AvcdWwmZZ2IjiLU9vt00\nHKsK833BbGJed9f7MnwOxLtYKCyXiBUW9VaazebEkCK/CrMt8XWFpfO6vbjY2nxu+iJlITaCWCdF\n2kWYb3NkvXq/Z0UPKyw+9EXP/uKgsFwivtmkzpJoNpsTORbb9tuWTOphhcV6K71eL9sIxg2SpEzE\n5q7Y5L0NhcVa5Ptd9rFRErPyKrSV4qCwXCKxUFjMY7GhML/DfjAYTHgqPhxm6/bpsZCykDfb3tuK\nD4X5bhS+4WSex8JQ2MVCYblEvLCox2KrXbzHMq0lhfdaer0eE/ikVNjwV8xj0SKX2CgJWzlpi1q8\nrWjvPN/qiDZycVBYLpFpHkus0sW791ZU/KGrM4CjVUn5iHUzthNVbfLe77oHkC2mrK2oXfi8ow+F\nUVyKh8Jywdi9J3YPi03ex0oogUQYNARmR6pqe3ztzmpbUtBASNmw3SXsUK+8QV5nacZqPXnrtfiG\nk7SXi4HCckHEuhj7Ekpfm+8Tkmo0JycnWbvvdruNdrt9qrTYJ+ppMKQM+CmRsbkr9rZt4WL3deXN\ntddREt5WYh4LbaY4KCwXiN8xf5aEpI0b2yFFaiydTgftdhvdbnfCWCgqpKzYvEre3BU7RdJ2M7ab\nITW3Epu7Yj0WLWphjuXioLBcEL7Kxe+6101fGgqzbSrsiswKi3osdlIkS4tJmZnmseR5L76Fy7RQ\nmB/XHQuFUVyKh8JyAdi8SiwhaT2WvBHEACZCYeqxaCjMeyxsokfKyqzxw15s8nIssVBYzGPJq5qk\nuBQHheUCyfNY/Gz7RqMx0SPMVrqoex/LsWjy3ofCCCkLebPt847Y6GG72z4WCovtZaHHcrFQWC4Y\nO3TINsjzjfL0vlZMOp0ODg8PcXBwgP39fezt7eHWrVvY39/H4eEhjo6O0O/36bGQSuC9B99I8uTk\nBMvLyxO2o+e13N4efuc9G05eHhSWC8SKit6OCYx6HHpdV2eHh4c4PDzE/v7+hLDs7e1NhMMGgwGN\nhVSCvLb3uthaXl6eEBQNj8VEZVqfMNrLxUJhuWD0CxzzWqyBjEajzM3Xy3a7HRWX/f39zM2nx0Kq\niPdYbKirXq9jNBpNXPoWLtZj8bvu7WtQYC4GCssFoJ6K/9msUJjeT1Fh8aGwg4ODidUZPRZSJbzH\nYkNhmoNUr149/Nv1WPzrkWKhsFwQsS/rtFCY7/E1Ho/RbrczUbHCcnh4OLEKo8dCqoD1IPzCS7/v\n/X4/S+LbSy8ozLFcLRSWSyIvDGZDYfZyOBxmYTDrsezt7eHw8DDq/RBSBWIei4bB7H4X2wIm5q34\nVi7MsVweFJYLxH55RSRreX9wcICbN29ibW0NtVoNKysr0VHDBwcHeOKJJ7Jkvc5b8d1ZCSkzfsEF\nACcnJ1mnCe34DQCrq6vR3mK9Xi/z7Pf39yeKW3S/l/Va9HXteyDFQWG5BPRLOxgMcHR0hIODA6ys\nrGRioyWUdlbEaDRCp9PBzZs3sbe3h06ng+PjY9bgk0oRE5UQQtad+PDwMOv0PRwOsbKyMlHkYj0W\nzUn6vV55e1j0tUjxUFguCFtqbNuzqLCICIbDIXq9Hur1+oQXooca1sHBAdrtNo6Pj9m+hVQK25bF\n/qzf7+Po6GhCVPr9PpaXlycqJ/VSPRxtPGk3R9oJkrE8C22peCgsF4jfx6Ieiw2L2RWZb4ynqzZd\neamw+BUXDYOUFf3O29u1Wi0TCisq3W43m65qRUUXaXYAng2B2bHefqoqbedikMv8xYrIQv8VtZ2L\nP2KbKAFMVMPYw6/uSLGEEGT2vS6WRbEV39JFr1tbsddtE0p7aE89TfLrpXr46qnYcDO5c/JshcJy\nycRGseYRExsKycVDYblcYrOLfDmxrQLT+9jDV1pOmxRJGyqOPFthKOyS4RebkEli+UhbuaW3bQNK\nP+vIFwH4Mnza3eVCYSGEXDleXPRnXmS8x6+XvvAlz8unuFwOFBZCyFxh//mPx+OokNhLe99YEQzF\n5PKhsBBC5gLfsNUyGo1O5STz+vHl5VMoMJcHhYUQMld4McjzUPzPYuEvisnVQGEhhMwlFIfyUrvq\nN0AIIaRaUFgIIYQUCoWFEEJIoVBYCCGEFAqFhRBCSKFQWAghhBQKhYUQQkihUFgIIYQUCoWFEEJI\noVBYCCGEFAqFhRBCSKFQWAghhBQKhYUQQkihUFgIIYQUCoWFEEJIoQhnHRBCCCkSeiyEEEIKhcJC\nCCGkUCgshBBCCoXCQgghpFAoLIQQQgqFwkIIIaRQKCyEEEIKhcJCCCGkUCgshBBCCoXCQgghpFAo\nLIQQQgqFwkIIIaRQKCyEEEIKhcJCCCGkUCgshBBCCoXCQgghpFAoLIQQQgqFwkIIIaRQKCyEEEIK\nhcJCCCGkUCgshBBCCuX/A4+u4v4AJiniAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a8ee1ee9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read some data to run the eval\n",
    "num_label_classes = 10\n",
    "reader_eval = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "\n",
    "eval_minibatch_size = 50\n",
    "eval_input_map = { input  : reader_eval.streams.features }\n",
    "\n",
    "eval_data = reader_eval.next_minibatch(eval_minibatch_size,\n",
    "                                  input_map = eval_input_map)\n",
    "\n",
    "img_data = eval_data[input].asarray()\n",
    "\n",
    "# Select a random image\n",
    "np.random.seed()\n",
    "idx = np.random.choice(eval_minibatch_size)\n",
    "\n",
    "orig_image = img_data[idx,:,:]\n",
    "decoded_image = model.eval(orig_image)[0]*255\n",
    "\n",
    "# Print image statistics\n",
    "def print_image_stats(img, text):\n",
    "    print(text)\n",
    "    print(\"Max: {0:.2f}, Median: {1:.2f}, Mean: {2:.2f}, Min: {3:.2f}\".format(np.max(img),\n",
    "                                                                              np.median(img),\n",
    "                                                                              np.mean(img),\n",
    "                                                                              np.min(img)))\n",
    "\n",
    "# Print original image\n",
    "print_image_stats(orig_image, \"Original image statistics:\")\n",
    "\n",
    "# Print decoded image\n",
    "print_image_stats(decoded_image, \"Decoded image statistics:\")\n",
    "\n",
    "\n",
    "# Define a helper function to plot a pair of images\n",
    "def plot_image_pair(img1, text1, img2, text2):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 6))\n",
    "\n",
    "    axes[0].imshow(img1, cmap=\"gray\")\n",
    "    axes[0].set_title(text1)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(img2, cmap=\"gray\")\n",
    "    axes[1].set_title(text2)\n",
    "    axes[1].axis(\"off\")\n",
    "# Plot the original and the decoded image\n",
    "img1 = orig_image.reshape(28,28)\n",
    "text1 = 'Original image'\n",
    "\n",
    "img2 = decoded_image.reshape(28,28)\n",
    "text2 = 'Decoded image'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.66685939,  0.        ,  0.41162193,\n",
       "         0.38101435,  0.7649737 ,  1.30843389,  0.        ,  0.46245933,\n",
       "         0.        ,  0.        ,  1.27721357,  0.33044845,  1.43980563,\n",
       "         0.88219088,  0.        ,  0.        ,  0.87134933,  0.2124386 ,\n",
       "         0.21936195,  0.        ,  0.58183432,  0.53038526,  1.92033005,\n",
       "         0.97121269,  0.28579801,  0.36218014,  1.05822837,  0.38342437,\n",
       "         0.        ,  0.51377368]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random image\n",
    "np.random.seed()\n",
    "idx = np.random.choice(eval_minibatch_size)\n",
    "network['sig'].eval(img_data[idx,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter('W', [], [392 x 784]),\n",
       " Parameter('b', [], [784]),\n",
       " Parameter('W', [], [32 x 392]),\n",
       " Parameter('b', [], [392]),\n",
       " Parameter('W', [], [32 x 32]),\n",
       " Parameter('b', [], [32]),\n",
       " Parameter('W', [], [392 x 32]),\n",
       " Parameter('b', [], [32]),\n",
       " Parameter('W', [], [784 x 392]),\n",
       " Parameter('b', [], [392]),\n",
       " Input('Input3344', [#], [784]),\n",
       " Constant('Constant3346', [], []),\n",
       " Parameter('W', [], [32 x 32]),\n",
       " Parameter('b', [], [32]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network['decoder'].inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
