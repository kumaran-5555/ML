{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the relevant modules\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import CNTK\n",
    "import cntk as C\n",
    "\n",
    "\n",
    "import cntk.io.transforms as xforms\n",
    "import cntk.tests.test_utils\n",
    "#C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "    \n",
    "import gzip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import struct\n",
    "import sys\n",
    "    \n",
    "import glob\n",
    "import socket\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "if socket.gethostname() == 'dsvm':\n",
    "    root = r'/home/kumaran/Data'\n",
    "else:\n",
    "    root = r'E:\\Temp'\n",
    "    \n",
    "data_dir = os.path.join(root, 'lfw')\n",
    "data_dir = os.path.join(root, 'MNIST')\n",
    "# down data from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
    "# model dimensions\n",
    "img_h = 28\n",
    "img_w  = 28\n",
    "input_dim = img_h * img_w\n",
    "num_channels = 3\n",
    "num_classes  = 0\n",
    "latent_dim = 32\n",
    "\n",
    "e_kernel_1 = (5,5)\n",
    "e_stride_1 = (2,2)\n",
    "e_filter_1 = 1\n",
    "e_filter_2 =  128\n",
    "\n",
    "isFast = False\n",
    "epoch_size = 30000        # 30000 samples is half the dataset size\n",
    "minibatch_size = 64\n",
    "num_sweeps_to_train_with = 10 if isFast else 1000\n",
    "num_samples_per_sweep = 60000\n",
    "num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) // minibatch_size\n",
    "num_samples_to_test = 10000\n",
    "\n",
    "#map_file = os.path.join(data_dir, 'cntk_image_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare CNTK imageReader data\n",
    "'''\n",
    "with open(map_file, 'w') as out:\n",
    "    for f in glob.glob(data_dir + '\\\\*\\\\*.jpg'):\n",
    "        out.write('{}\\t0\\n'.format(f))\n",
    "'''\n",
    "def plot_image(img1, img2):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 6))\n",
    "\n",
    "    axes[0].imshow(img1, cmap=\"gray\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(img2, cmap=\"gray\")    \n",
    "    axes[1].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reader_mnist(path, is_training):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels = C.io.StreamDef(field='labels', shape=10, is_sparse=False),\n",
    "        input   = C.io.StreamDef(field='features', shape=784, is_sparse=False)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "def create_reader_lfw(map_file, train, is_training):\n",
    "    print(\"Reading map file:\", map_file)    \n",
    "\n",
    "    if not os.path.exists(map_file):\n",
    "        raise RuntimeError(\"This tutorials depends 201A tutorials, please run 201A first.\")\n",
    "\n",
    "    # transformation pipeline for the features has jitter/crop only when training\n",
    "    transforms = []\n",
    "    # train uses data augmentation (translation only)\n",
    "    if train and False:\n",
    "        transforms += [\n",
    "            xforms.crop(crop_type='randomside', side_ratio=0.8)\n",
    "        ]\n",
    "    transforms += [\n",
    "        xforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear')        \n",
    "    ]\n",
    "    # deserializer\n",
    "    return c.io.MinibatchSource(c.io.ImageDeserializer(map_file, c.io.StreamDefs(\n",
    "        input = c.io.StreamDef(field='image', transforms=transforms), # first column in map file is referred to as 'image'\n",
    "        labels   = c.io.StreamDef(field='label', shape=num_classes)      # and second as 'label'\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encoder_cnn(input):    \n",
    "    with C.layers.default_options(init=C.normal(scale=0.02)):\n",
    "\n",
    "        dfc_dim = 1024\n",
    "        df_dim = 64\n",
    "\n",
    "        print('Discriminator convolution input shape', input.shape)\n",
    "        x = C.reshape(input, (1, img_h, img_w))\n",
    "\n",
    "        h0 = C.layers.Convolution2D(e_kernel_1, e_filter_1, strides=e_stride_1, pad=True, activation=C.relu)(x)        \n",
    "        print('h0 shape :', h0.shape)\n",
    "                \n",
    "        h1 = C.layers.Convolution2D(e_kernel_1, e_filter_2, strides=e_stride_1, pad=True, activation=C.relu)(h0)        \n",
    "        print('h1 shape :', h1.shape)\n",
    "        \n",
    "        \n",
    "        mu = C.layers.Dense(latent_dim, activation=None)(h1)        \n",
    "        print('mu shape :', mu.shape)\n",
    "        \n",
    "        sig = C.layers.Dense(latent_dim, activation=C.relu, init=C.normal(scale=2))(h1)\n",
    "        print('sig shape :', sig.shape)\n",
    "\n",
    "        return mu, sig\n",
    "    \n",
    "def decoder_cnn(z):\n",
    "    with C.layers.default_options(init=C.normal(scale=0.02)):\n",
    "        \n",
    "        \n",
    "        print('Generator input shape: ', z.shape)\n",
    "        s_h2, s_w2 = img_h//2, img_w//2 #Input shape (14,14)\n",
    "        s_h4, s_w4 = img_h//4, img_w//4 # Input shape (7,7)\n",
    "        gfc_dim = 1024\n",
    "        gf_dim = 64\n",
    "        \n",
    "        h1 = C.layers.Dense([e_filter_2, s_h4,  s_w4], activation=C.relu)(z)        \n",
    "        print('h1 shape', h1.shape)\n",
    "\n",
    "        h2 = C.layers.ConvolutionTranspose2D(e_kernel_1,\n",
    "                                  num_filters=e_filter_1,\n",
    "                                  strides=e_stride_1,\n",
    "                                  pad=True,\n",
    "                                  output_shape=(s_h2, s_w2), activation=C.relu)(h1)        \n",
    "        print('h2 shape', h2.shape)\n",
    "\n",
    "        h3 = C.layers.ConvolutionTranspose2D(e_kernel_1,\n",
    "                                  num_filters=e_filter_1,\n",
    "                                  strides=e_stride_1,\n",
    "                                  pad=True,\n",
    "                                  output_shape=(img_h, img_w),\n",
    "                                  activation=C.sigmoid)(h2)\n",
    "        print('h3 shape :', h3.shape)\n",
    "\n",
    "        return C.reshape(h3, img_h * img_w)\n",
    "\n",
    "def decoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(200, activation = C.relu), \n",
    "                               C.layers.Dense(input_dim, activation=C.sigmoid)])(input)\n",
    "    return intermediate\n",
    "    \n",
    "def encoder(input):\n",
    "    intermediate = C.layers.Sequential([C.layers.Dense(200, activation = C.relu), \n",
    "                               C.layers.Dense(latent_dim, activation=C.relu)])(input)\n",
    "    \n",
    "    mu = C.layers.Dense(latent_dim, activation=None)(intermediate)\n",
    "    sigma = C.layers.Dense(latent_dim, activation=C.relu)(intermediate)\n",
    "\n",
    "    \n",
    "    return mu, sigma\n",
    "network = {}\n",
    "\n",
    "\n",
    "def create_network():\n",
    "    input = C.input_variable(input_dim)\n",
    "    label = C.input_variable(input_dim)\n",
    "    network['input'] = input\n",
    "    network['label'] = label\n",
    "\n",
    "    # Create the model function\n",
    "    mu, sig = encoder(input/255.0)\n",
    "    \n",
    "    \n",
    "    z = C.random.normal_like(mu, mean=0, scale=1)\n",
    "    z = mu + z * sig\n",
    "    network['mu'] = mu\n",
    "    network['sig'] = sig\n",
    "    \n",
    "    z_placeholder = C.placeholder()            \n",
    "    output = C.as_block(decoder(z_placeholder), [(z_placeholder, z)], 'Decoder', 'Decoder_1')    \n",
    "    network['output'] = output\n",
    "    target = input/255.0\n",
    "    construction_loss = C.losses.squared_error(target, output)\n",
    "    \n",
    "    l1 = C.element_times(target, C.log(output))\n",
    "    l2 = C.element_times(1.0-target, C.log(1.0-output))\n",
    "    print(l1.shape)\n",
    "    print(l2.shape)\n",
    "                         \n",
    "    #construction_loss = C.reduce_sum(-1 * C.plus(l1, l2))\n",
    "    #print(construction_loss.shape)\n",
    "                                     \n",
    "    \n",
    "    log_stddev = C.log(sig)\n",
    "    kl_loss = - 0.5 * (1 + log_stddev - C.square(mu) - C.square(C.exp(log_stddev)))\n",
    "    loss = construction_loss + 3 * kl_loss\n",
    "    \n",
    "    error  = C.classification_error(output, target)\n",
    "    network['loss'] = loss\n",
    "    network['error'] = error\n",
    "    return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(784,)\n",
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/cntk/learners/__init__.py:340: RuntimeWarning: When providing the schedule as a number, epoch_size is ignored\n",
      "  warnings.warn('When providing the schedule as a number, epoch_size is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per 1 samples: 3e-05\n",
      " 7.93e+03   7.93e+03        0.7        0.7            64\n",
      " 7.96e+03   7.97e+03      0.746      0.769           192\n",
      " 7.91e+03   7.87e+03      0.784      0.812           448\n",
      " 7.72e+03   7.56e+03      0.798      0.811           960\n",
      " 7.21e+03   6.74e+03      0.743      0.692          1984\n",
      " 5.61e+03   4.06e+03      0.608      0.477          4032\n",
      " 4.11e+03   2.63e+03      0.539       0.47          8128\n",
      " 3.17e+03   2.24e+03      0.454      0.369         16320\n",
      " 2.55e+03   1.92e+03      0.349      0.245         32704\n",
      " 2.09e+03   1.64e+03      0.271      0.194         65472\n",
      " 1.72e+03   1.35e+03      0.203      0.135        131008\n",
      " 1.41e+03    1.1e+03       0.15      0.098        262080\n",
      " 1.18e+03        958       0.11      0.069        524224\n",
      "      957        730     0.0783     0.0469       1048512\n",
      "      773        588     0.0553     0.0323       2097088\n",
      "      656        539     0.0407      0.026       4194240\n",
      "      536        416     0.0302     0.0196       8388544\n",
      "      458        379     0.0235     0.0168      16777152\n",
      "      411        364     0.0196     0.0157      33554368\n",
      "Average training error: 1.77%\n",
      "Average test error: 1.40%\n"
     ]
    }
   ],
   "source": [
    "def train(train_file, test_file):\n",
    "    create_network()\n",
    "    \n",
    "    loss = network['loss']\n",
    "    output = network['output']\n",
    "    error = network['error']\n",
    "    input = network['input']\n",
    "    label = network['label']\n",
    "    \n",
    "     # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = [0.00003]\n",
    "    lr_schedule = C.learning_parameter_schedule_per_sample(lr_per_sample, epoch_size)\n",
    "    # Momentum which is applied on every minibatch_size = 64 samples\n",
    "    momentum_schedule = C.momentum_schedule(0.9126265014311797, minibatch_size)\n",
    "    # We use a variant of the Adam optimizer which is known to work well on this dataset\n",
    "    # Feel free to try other optimizers from\n",
    "    # https://www.cntk.ai/pythondocs/cntk.learner.html#module-cntk.learner\n",
    "    learner = C.fsadagrad(output.parameters,\n",
    "                         lr=lr_schedule, momentum=momentum_schedule)\n",
    "\n",
    "    # Instantiate the trainer\n",
    "    progress_printer = C.logging.ProgressPrinter(0)\n",
    "    trainer = C.Trainer(output, (loss, error), learner, progress_printer)\n",
    "\n",
    "    # Map the data streams to the input and labels.\n",
    "    # Note: for autoencoders input == label\n",
    "    input_map = {\n",
    "        input  : train_file.streams.input,\n",
    "        label  : train_file.streams.labels\n",
    "    }\n",
    "    \n",
    "    test_input_map = {\n",
    "        input  : test_file.streams.input,\n",
    "        label  : test_file.streams.labels\n",
    "    }\n",
    "    aggregate_metric = 0\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        # Read a mini batch from the training data file\n",
    "        data = train_file.next_minibatch(minibatch_size, input_map = input_map)\n",
    "\n",
    "        # Run the trainer on and perform model training\n",
    "        trainer.train_minibatch(data)\n",
    "        samples = trainer.previous_minibatch_sample_count\n",
    "        aggregate_metric += trainer.previous_minibatch_evaluation_average * samples\n",
    "\n",
    "    train_error = (aggregate_metric*100.0) / (trainer.total_number_of_samples_seen)\n",
    "    print(\"Average training error: {0:0.2f}%\".format(train_error))\n",
    "    \n",
    "    metric_numer = 0.0\n",
    "    metric_denom = 0\n",
    "    while True:        \n",
    "        data = test_file.next_minibatch(minibatch_size,\n",
    "                                       input_map = test_input_map)\n",
    "        n = minibatch_size\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        metric_numer += np.abs(eval_error * n)\n",
    "        metric_denom += n\n",
    "        if metric_denom > num_samples_to_test:\n",
    "            break\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    test_error = (metric_numer*100.0) / (metric_denom)\n",
    "    print(\"Average test error: {0:0.2f}%\".format(test_error))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "train_file = create_reader_mnist(os.path.join(data_dir, 'Train-28x28_cntk_text.txt'), True)\n",
    "test_file = create_reader_mnist(os.path.join(data_dir, 'Test-28x28_cntk_text.txt'), True)\n",
    "\n",
    "train(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_reader_mnist(os.path.join(data_dir, 'Test-28x28_cntk_text.txt'), False)\n",
    "input_map = {\n",
    "        network['input']  : test.streams.input,\n",
    "        network['label']  : test.streams.labels\n",
    "    }\n",
    "data = test.next_minibatch(minibatch_size, input_map=input_map)\n",
    "output = network['output'].eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62b313ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed()\n",
    "idx = np.random.choice(minibatch_size)\n",
    "in_img = data[network['input']].data.asarray()[idx,:,:].reshape(img_h, img_w)\n",
    "out_img = output[idx,:].reshape(img_h, img_w)\n",
    "plot_image(in_img, out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = network['output'].find_by_name('Decoder_1')\n",
    "\n",
    "\n",
    "x = d.clone('freeze', {d.arguments[0] : C.input_variable(32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10420056, 0.05136432, 0.7037908 , 0.03697184, 0.15334131,\n",
       "        0.09455513, 0.69782317, 0.6993763 , 0.02331698, 0.71096873,\n",
       "        0.7074536 , 0.70187664, 0.0984471 , 0.6965998 , 0.03551479,\n",
       "        0.7072985 , 0.7063538 , 0.09296692, 0.        , 0.70113   ,\n",
       "        0.11381146, 0.07403749, 0.04187953, 0.04686376, 0.06191485,\n",
       "        0.04002539, 0.03969197, 0.09273525, 0.08007951, 0.70278454,\n",
       "        0.05984713, 0.09677937]], dtype=float32)"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f62b3149be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed()\n",
    "idx = np.random.choice(minibatch_size)\n",
    "C.cntk_py.set_fixed_random_seed(idx)\n",
    "random = C.random.normal((32), mean=0, scale=1)\n",
    "plot_image(x.eval(random.eval()).reshape(img_h, img_w) , data[network['input']].data.asarray()[idx,:,:].reshape(img_h, img_w)) \n",
    "\n",
    "network['sig'].eval(data[network['input']].data.asarray()[idx,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x.eval(C.random.normal((32), mean=0, scale=1).eval()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
