{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 60.12101468,   3.81959507,   0.33058341]),\n",
       " array([[ 0.99948847,  0.03190282,  0.00223751],\n",
       "        [ 0.03192172, -0.99944995, -0.00898854],\n",
       "        [-0.00194952, -0.00905537,  0.9999571 ]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# to demonstrate, we create either 2D or 3D ellipse and show that\n",
    "# Principle compontent are aliged with ellipse primary axis \n",
    "rows = 100\n",
    "cols = 3\n",
    "x = np.zeros((rows, cols))\n",
    "for i in range(rows):\n",
    "    offset = np.random.uniform(-10,10,1)\n",
    "    #print(x[i,:], offset)\n",
    "    r = np.random.uniform(-10,10,1)\n",
    "    x[i,0] = np.random.uniform(-10,10,1) + np.random.normal(0, 5, 1)\n",
    "    x[i,1] = np.random.uniform(-3,3,1)+ np.random.normal(0, 1, 1)\n",
    "    x[i,2] = np.random.uniform(-1,1,1)+ np.random.normal(0, 0.001, 1)\n",
    "    #x[i,2] = 0\n",
    "    \n",
    "    #x[i,0] = r  + np.random.normal(0,1,1)\n",
    "    #x[i,1] = r/2  + np.random.normal(0,1,1)\n",
    "    #print(x[i,:])\n",
    "\n",
    "    \n",
    "#x[:,2] += x[:,0] * 0.5\n",
    "#x[:,1] = x[:,0]\n",
    "\n",
    "'''\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.set_zlim(-20, 20)\n",
    "\n",
    "ax.plot(x[:,0], x[:,1], x[:,2], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
    "plt.title('Samples for class 1 and class 2')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "# remove mean \n",
    "mean = x.mean(axis=0)\n",
    "\n",
    "x_ = x - mean\n",
    "'''\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.set_zlim(-20, 20)\n",
    "\n",
    "ax.plot(x_[:,0], x_[:,1], x_[:,2], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
    "plt.title('Samples for class 1 and class 2')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "\n",
    "# compute covariance matrix \n",
    "# default computation uses scalin of 1/(# of rows - 1)\n",
    "# multiply by row-1 to rescale\n",
    "\n",
    "cov1 = np.cov(x_.T)\n",
    "cov1\n",
    "\n",
    "# manual computation of covariance\n",
    "# cov2[i,j] = x[:,i] . x[:,j]\n",
    "cov2 = np.zeros((3,3))\n",
    "\n",
    "for i in range(cols):\n",
    "    for j in range(cols):\n",
    "        cov2[i,j] = x_[:,i].dot(x_[:,j])\n",
    "cov2\n",
    "\n",
    "cov2 - cov1\n",
    "\n",
    "# compute the eigen value of covariance matrix\n",
    "eigenValues, eigenVectors = np.linalg.eig(cov1)\n",
    "eigenValues, eigenVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the eigen vector and see that it matches variance direction\n",
    "\n",
    "def plot(v, c, l):\n",
    "    global ax\n",
    "    ax.plot([0,v[0]],[0,v[1]],[0,v[2]], c=c, label=l)\n",
    "    \n",
    "%matplotlib qt\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.set_zlim(-20, 20)\n",
    "\n",
    "ax.plot(x_[:,0], x_[:,1], x_[:,2], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
    "plt.title('Samples for class 1 and class 2')\n",
    "ax.legend(loc='upper right')\n",
    "plot(eigenVectors[:,0]*10, 'r', '$u_1$')\n",
    "plot(eigenVectors[:,1]*10, 'b', '$u_2$')\n",
    "plot(eigenVectors[:,2]*10,'y', '$v_3$')\n",
    "#ax.plot(x_.dot(eigenVectors[0]), np.zeros((100,1)), np.zeros((100,1)), '^',color='red', alpha=0.5, label='class1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=3)\n",
    "sklearn_transf = sklearn_pca.fit_transform(x_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sklearn_pca.explained_variance_\n",
    "\n",
    "sklearn_pca.components_\n",
    "\n",
    "# plot the eigen vector and see that it matches variance direction\n",
    "\n",
    "def plot(v, c, l):\n",
    "    global ax\n",
    "    ax.plot([0,v[0]],[0,v[1]],[0,v[2]], c=c, label=l)\n",
    "    \n",
    "%matplotlib qt\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlim(-20,20)\n",
    "ax.set_ylim(-20, 20)\n",
    "ax.set_zlim(-20, 20)\n",
    "\n",
    "ax.plot(x_[:,0], x_[:,1], x_[:,2], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
    "plt.title('Samples for class 1 and class 2')\n",
    "ax.legend(loc='upper right')\n",
    "plot(sklearn_pca.components_[0]*10, 'r', '$u_1$')\n",
    "plot(sklearn_pca.components_[1]*10, 'b', '$u_2$')\n",
    "plot(sklearn_pca.components_[2]*10,'y', '$v_3$')\n",
    "#ax.plot(x_.dot(eigenVectors[0]), np.zeros((100,1)), np.zeros((100,1)), '^',color='red', alpha=0.5, label='class1')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
